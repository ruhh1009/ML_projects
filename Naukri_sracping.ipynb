{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing selenium and importing all important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\priya\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from selenium) (1.25.8)\n"
     ]
    }
   ],
   "source": [
    "# Let's first install the selenium library\n",
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data on naukri portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com'\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding element for job search bar\n",
    "search_job= driver.find_element_by_id(\"qsb-keyword-sugg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write on search bar\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding element for job location bar and write on location bar\n",
    "search_loc= driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click using xpath function\n",
    "search_btn= driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Data Scientist',\n",
       " 'Big Data - Data Scientist',\n",
       " 'Specialist I - Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'SDE Lead Data Scientist-L3',\n",
       " 'Computational Design Lead Data Scientist-L3',\n",
       " 'Hiring For DATA Scientist - ON Contract Basis (3-6 Months)',\n",
       " 'Senior Data Scientist']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles=[]\n",
    "for i in titles_tags:\n",
    "    job_titles.append(i.text)\n",
    "job_titles=job_titles[:10]\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having companies name\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Wipro Limited',\n",
       " 'Xoriant Solutions Pvt Ltd',\n",
       " 'Philips India Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Oracle India Pvt. Ltd.',\n",
       " 'Huawei Technologies India Pvt Ltd',\n",
       " 'Huawei Technologies India Pvt Ltd',\n",
       " 'GlobalEdx Learning and Technology Solution Pvt Ltd',\n",
       " 'GO-JEK India']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_names=[]\n",
    "for i in companies_tags:\n",
    "    company_names.append(i.text)\n",
    "company_names=company_names[:10]\n",
    "company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having experience\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '4-9 Yrs',\n",
       " '1-3 Yrs',\n",
       " '4-7 Yrs',\n",
       " '6-8 Yrs',\n",
       " '6-10 Yrs',\n",
       " '5-8 Yrs',\n",
       " '5-8 Yrs',\n",
       " '3-8 Yrs',\n",
       " '4-11 Yrs']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience_list=[]\n",
    "for i in experience_tags:\n",
    "    experience_list.append(i.text)\n",
    "experience_list=experience_list[:10]\n",
    "experience_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having location\n",
    "locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Kochi/Cochin, Indore, Hyderabad/Secunderabad, Pune, Ahmedabad, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_list=[]\n",
    "for i in locations_tags:\n",
    "    location_list.append(i.text)\n",
    "location_list=location_list[:10]\n",
    "location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Finding length of job_title, company_name, experience_list and location_list\n",
    "print(len(job_titles),len(company_names),len(experience_list),len(location_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles\n",
    "jobs['company']=company_names\n",
    "jobs['experience_required']=experience_list\n",
    "jobs['location']=location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Chennai, Bang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data - Data Scientist</td>\n",
       "      <td>Xoriant Solutions Pvt Ltd</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specialist I - Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SDE Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Computational Design Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For DATA Scientist - ON Contract Basis ...</td>\n",
       "      <td>GlobalEdx Learning and Technology Solution Pvt...</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>GO-JEK India</td>\n",
       "      <td>4-11 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                     Data Scientist   \n",
       "2                          Big Data - Data Scientist   \n",
       "3                      Specialist I - Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                         SDE Lead Data Scientist-L3   \n",
       "7        Computational Design Lead Data Scientist-L3   \n",
       "8  Hiring For DATA Scientist - ON Contract Basis ...   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                             company experience_required  \\\n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs   \n",
       "1                                      Wipro Limited             4-9 Yrs   \n",
       "2                          Xoriant Solutions Pvt Ltd             1-3 Yrs   \n",
       "3                              Philips India Limited             4-7 Yrs   \n",
       "4                             IBM India Pvt. Limited             6-8 Yrs   \n",
       "5                             Oracle India Pvt. Ltd.            6-10 Yrs   \n",
       "6                  Huawei Technologies India Pvt Ltd             5-8 Yrs   \n",
       "7                  Huawei Technologies India Pvt Ltd             5-8 Yrs   \n",
       "8  GlobalEdx Learning and Technology Solution Pvt...             3-8 Yrs   \n",
       "9                                       GO-JEK India            4-11 Yrs   \n",
       "\n",
       "                                            location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1  Kolkata, Hyderabad/Secunderabad, Chennai, Bang...  \n",
       "2  Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data on naukri portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com'\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding element for job search bar\n",
    "search_job= driver.find_element_by_id(\"qsb-keyword-sugg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write on search bar\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding element for job location bar and write on location bar\n",
    "search_loc= driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click using xpath function\n",
    "search_btn= driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having job titles\n",
    "titles_tags2=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Data Scientist',\n",
       " 'Big Data - Data Scientist',\n",
       " 'Specialist I - Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'SDE Lead Data Scientist-L3',\n",
       " 'Computational Design Lead Data Scientist-L3',\n",
       " 'Hiring For DATA Scientist - ON Contract Basis (3-6 Months)',\n",
       " 'Senior Data Scientist']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles2=[]\n",
    "for i in titles_tags2:\n",
    "    job_titles2.append(i.text)\n",
    "job_titles2=job_titles2[:10]\n",
    "job_titles2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having company name\n",
    "companies_tags2=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Wipro Limited',\n",
       " 'Xoriant Solutions Pvt Ltd',\n",
       " 'Philips India Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Oracle India Pvt. Ltd.',\n",
       " 'Huawei Technologies India Pvt Ltd',\n",
       " 'Huawei Technologies India Pvt Ltd',\n",
       " 'GlobalEdx Learning and Technology Solution Pvt Ltd',\n",
       " 'GO-JEK India']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_names2=[]\n",
    "for i in companies_tags2:\n",
    "    company_names2.append(i.text)\n",
    "company_names2=company_names2[:10]\n",
    "company_names2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having location\n",
    "locations_tags2=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Kochi/Cochin, Indore, Hyderabad/Secunderabad, Pune, Ahmedabad, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_list2=[]\n",
    "for i in locations_tags2:\n",
    "    location_list2.append(i.text)\n",
    "location_list2=location_list2[:10]\n",
    "location_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-data-scientist-data-analyst-business-analyst-inflexion-analytix-private-limited-mumbai-hyderabad-secunderabad-pune-gurgaon-gurugram-chennai-bangalore-bengaluru-0-to-3-years-100521000368?src=jobsearchDesk&sid=16217626645701148&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-wipro-limited-kolkata-hyderabad-secunderabad-chennai-bangalore-bengaluru-4-to-9-years-210521000038?src=jobsearchDesk&sid=16217626645701148&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-big-data-data-scientist-xoriant-solutions-pvt-ltd-kochi-cochin-indore-hyderabad-secunderabad-pune-ahmedabad-bangalore-bengaluru-mumbai-all-areas-1-to-3-years-130521005018?src=jobsearchDesk&sid=16217626645701148&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-specialist-i-data-scientist-philips-india-limited-bangalore-bengaluru-4-to-7-years-170521500993?src=jobsearchDesk&sid=16217626645701148&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-ibm-india-pvt-limited-bangalore-bengaluru-6-to-8-years-110521907352?src=jobsearchDesk&sid=16217626645701148&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-oracle-india-pvt-ltd-bangalore-bengaluru-6-to-10-years-190521008276?src=jobsearchDesk&sid=16217626645701148&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-sde-lead-data-scientist-l3-huawei-technologies-india-pvt-ltd-bangalore-bengaluru-5-to-8-years-120521901434?src=jobsearchDesk&sid=16217626645701148&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-computational-design-lead-data-scientist-l3-huawei-technologies-india-pvt-ltd-bangalore-bengaluru-5-to-8-years-120521901329?src=jobsearchDesk&sid=16217626645701148&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-hiring-for-data-scientist-on-contract-basis-3-6-months-globaledx-learning-and-technology-solution-pvt-ltd-hyderabad-secunderabad-bangalore-bengaluru-mumbai-all-areas-3-to-8-years-170521003581?src=jobsearchDesk&sid=16217626645701148&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-go-jek-india-bangalore-bengaluru-4-to-11-years-190521500736?src=jobsearchDesk&sid=16217626645701148&xp=10&px=1']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching URL\n",
    "url=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    url.append(i.get_attribute(\"href\"))\n",
    "url=url[:10]\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having job description\n",
    "Job_description=[]\n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        job_desc=driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "        Job_description.append(job_desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Job_description.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Job description\\nJob Role : Data Scientist/Data Analyst /Business Analyst\\n\\nLocation : Chennai/Bangalore/Hyderabad/Pune/Mumbai/Delhi\\n\\nGreetings from CAIA - Center for Artificial Intelligence & Advanced Analytics\\n43% of companies experienced a high deficit of skilled resources with Advanced Analytical skills and AI implementing capabilities in year 2020. CAIA gives you a great opportunity to enter the world of future technologies and Innovations- Data Science, Analytics, AI, Data Visualization and Cloud Computing.\\n\\nWhile 2020 was a year like no other, we are living in an interesting times where data is reshaping the world, and businesses are rapidly adopting technology to gain an edge over others. Hence, there's a substantial increase in demand for technology professionals who can implement systems in data science, machine learning and AI in Tier 1 and Tier 2 organization's working closely with us.\\n\\nTo help you build a sustainable career we would like you to utilize data, software and Analytical approaches in Data Science and AI to up skill and get recruited into an organization appreciating your skilling journey.\\nApplications invited from all Freshers and experienced candidates (0-3 yrs) aspiring to make a career in Artificial Intelligence and Advanced Analytics and Data Science.\\nIf you wish to make a shift in your career or undergo a career transition, upskilling is essential since it allows you to learn more about the domain and acquire the required skills.\\n\\nCall to schedule interview Monday -Saturday from 10:00 am to 7Pm\\n\\nManigandan -+91 7299917200\\n\\nEmail : manigandan@centerforaia.com\\n\\nWhat is needed from you?\\n\\nFreshers who wish to start their career in Analytics and AI and professionals who wish to\\nupskill or change their domain to analytics and emerging technologies are free to apply.\\nAn Educational background in any one of the following- BE/B.Tech, ME/M Tech, MSc, BSc/MSc Maths and Statistics, B Com, BCA, BSc CS, BSC IT, MSC IT, MCA\\nSkills relating to Mathematics/Statistics.\\nNatural passion towards numbers, business, coding, Analytics and Artificial Intelligence, Machine Learning, visualization\\nGood verbal and written communication skills\\nAbility to understand domains in businesses across various sectors\\n\\n\\nSelection procedure includes\\n\\nAptitude Test & Communication Exam - Online / Offline\\nSQL/Python test - Online / Offline\\n\\nCandidates who clears the above will have one-one discussion with our Career Guidance Manager for further evaluation and processing of your Resume.\\n\\n\\nAll the Shortlisted candidates will be eligible to continue the corporate training with CAIA\\nWhat you can expect from us?\\n\\nYou will get trained on the following modules for a period of 12-14 weeks:\\n\\nSQL & PLSQL\\nData Wrangling using Python\\nData Visualization Using Power-BI\\nStatistics for Machine Learning\\nArtificial Intelligence, Data Interpretation\\nSupervised & Unsupervised Learning,\\nNLP & Deep Learning\\nCloud Data Lake\\nBusiness intelligence & Data Visualization\\nSimulation Projects\\nExpected Outcome?\\n\\nAt the end of the Training you are expected to be well versed with the following:\\n\\nAnalysis of large and complex data sets from multiple sources\\nDevelopment and evaluation of data analytics models, algorithms and solutions\\nUnderstanding/implementation of ML algorithms, performance tuning and reporting\\nImplementation of algorithms to mine targeted data and the ability to convert data in to a business story\\nTranslation of business requirements into technical requirements; Data extraction, preparation and transformation\\nIdentification, development and implementation of statistical techniques and algorithms that address business challenges and adds value to the organization\\nRequirement Analysis and communication of findings in the form of a meaningful story with the stakeholders\\nFinding analytical solutions to abstract business issues.\\nApply objective analysis of facts before coming to a conclusion\\n\\nAbout CAIA - Inflexion Analytix Private Limited\\n\\nCenter for Artificial Intelligence and Advanced Analytics (Center for AIA) is the brainchild of experienced and visionary alumni of IIT Madras and Bombay.\\nDigital leaders - 5F World and Systech Solutions have joined hands to create a venture for architecting the future of society, workforce, governments and businesses. 5F World specializes in designing solutions around digital platforms and Systech Solutions has an expertise in architecting Artificial Intelligence and Advance Analytics solutions for Fortune 500 companies.\\nOur Website : http://www.centerforaia.com/\\n\\nhttps://inflexion-analytix-private-limited.business.site/?m=true\\n\\nCenter for Artificial Intelligence & Advanced Analytics (CAIA) focuses on the following:\\n\\n1. Global Research on emerging trends, technologies and applications in AI and Advanced Analytics\\n2. Advanced Training programs for readying the future ready workforce\\n3. Solutions to herald the futuristic lifestyle and workspaces in the field of AI and Data Science.\\nRoleData Analyst\\nIndustry TypeBPO / Call Centre\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nBusiness IntelligenceArtificial IntelligenceBig DataITMachine LearningStatisticsDeep LearningAnalyticsBusiness AnalysisSQLData ScienceNLPCloud ComputingData VisualizationSoftwareData WarehousingPython\",\n",
       " 'Job description\\nRole: Data Scientist\\n\\nRoles and Responsibilities\\nSuitable candidates will be part of Wipro Digital-Intelligent Enterprise practice. The role entails leveraging Data Science and Machine Learning to solve typical problems within an organization and create IP that could be deployed in a productized mode. This will entail significant hands-on work on multiple Big Data Technologies, Data Analysis, Identifying data patterns, ML models, Insights generation. The role entails deployment in a customer context and managing customer expectations.\\n\\nTechnical Skills Required:\\nHands on with Python or R\\nAnalytics using industry leading BI tools and technologies\\nImplementation knowledge of supervised\\\\un-supervised machine learning algorithms\\nGood statistical analysis skills for data pre-processing and data wrangling\\nExperienced in using big data frameworks like Hadoop\\nKnowledge of business intelligence tools or reporting tools\\n\\nData Preparation for Modeling\\nMissing Data Imputation,Outlier Treatment\\nScaling, Normalization, Standardization\\nEncoding for Categorical Variables\\nOversampling\\\\Undersampling for reducing class imbalance\\n\\nExperience in building solutions using Model Library\\nFeature Selection\\nTree-based Ensemble Models\\nGradient\\\\Adaptive Boosted Trees\\nHyper-parameter tuning\\nBuilding Prediction mechanisms using methods like Logistic regression, voting classifier stacking etc\\n\\n\\n\\nRoleSoftware Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nKey Skills\\nData ScienceMachine LearningPython\\nLogistic RegressionData WranglingHadoopData AnalysisBig DataStatistical Analysis\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " '-',\n",
       " 'Job description\\nResponsibilities and Key Result Areas\\nDesign and develop project prototypes and solutions.\\nParticipate in project estimation, planning and risk management activities\\nIs responsible for delivering input in the planning process to the project leader\\nEnsures that there is proper documentation for the developed solutions.\\nEnsure compliance to the Quality Management System and regulatory requirements\\nKey Technical Skills:\\n4 - 7 yrs years of experience in data science\\nDeveloped Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification,\\ntree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.\\nProficient and hands on experience in developing models using concepts of Artificial Intelligence,\\nMachine Learning and Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)\\nExperience with containers like Docker is added advantage\\nExperience in Sql\\nWorking experience in agile/SAFe development methodologies\\nSoft Skill set:\\nFast learner. Ability to grasp key concepts quickly with minimal or no supervision\\nGo-Getter Attitude. Ability to take ownership of team goals and deliver it with quality and within required timeline\\nTeam Player attitude. Key characteristic of the individual who puts the team first before self.\\nAbility to think out of box: Ability to come up with bright ideas and always looking at the next big thing in technology\\nFlexible and willingness to stretch oneself when needed.\\nRoleSoftware Developer\\nIndustry TypeMedical Services / Hospital\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Post Graduation Not Required\\nKey Skills\\nMiningdeep learningdata scienceArtificial IntelligenceMachine learningAgileHTMLRisk managementMATLABSQL',\n",
       " '-',\n",
       " '-',\n",
       " 'Job description\\nBusiness & Team overview:\\nFounded in 1987, Huawei is a leading global provider of ICT (information and communications technology) infrastructure and smart devices. We are committed to bringing digital to every person, home and organization for a fully connected, intelligent world. We have nearly 194,000 employees, and we operate in more than 170 countries and regions, serving more than 3 billion people around the world.\\n\\nHuawei Technologies has three business directions: Carrier Business Group, which provides innovative and secure network equipment to telecom carriers, including the leading 5G mobile network.\\nEnterprise Business Group, which provides facilities and solutions to big and small companies, including IT facilities.\\nConsumer Business Groups, which provides devices to the customer, including mobile phones, PC, tablet, TV, audio, glasses, watches, locomotives, and headphones. And also provide solutions on mobile offices, smart homes, sports and health, audio-visual entertainment, and smart travel products.\\n\\nThis opportunity is belong to Huawei Consumer Business Group.\\n\\nDriven by the coordinated development of \"Chip-Device-Cloud\", consumer products such as smartphones are becoming increasingly intelligent and pervasive. The era of smart services is the future.\\n\\nHuawei Ads Services is dedicated to provide Huawei end-users with high-quality digital experiences, to build a business closed-loop system for Developers and Improve the ROI for the Advertisers\\n.\\nIn 2020 Q1, along with more than 650 million users and 1,400,000 registered developers worldwide, we have the following unique advantages:\\n1. With All-scenario intelligent solution, the Huawei devices become super entrance of traffic, including mobile phones, PC, tablet, TV, audio, glasses, watches, locomotives, and head phones\\n2. This team will be responsible for building a new Ad Serving Platform and have the opportunity to define the product for our Huawei end-users.\\n3. AI-Driven is the direction of Ads, Huawei is going to build a strong team in India to Innovate and deliver AI-driven Smart Ad Serving Platforms\\n\\nJob Title: Lead Data Scientist\\nWe are looking for a Lead data scientist who will help us discover the information hidden in vast amounts of Ad Campaign data, and help us to optimize the campaign to improve the advertiser ROI and improve the overall consumer experience. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems using Deep learning algorithms integrated with our products. Some the key area you will be working on spend recommendation, floor price prediction, CTR/CVR prediction, market funnel analysis and perdition of lead to conversion, etc.\\n\\nResponsibility:\\nAnalyze the data, develop insights and identify the opportunity to utilize the data to predict various Advertisement key indicators like CTR, CVR, Inventory and Develop prediction and optimization algorithms for campaign, look alike modeling, etc for Huawei Ads.\\nTakeup key challenges in AI-driven Smart Ad Serving Platform and focus on research and developing leading AI algorithms and productionize for Huawei Ads.\\nTakeup initiative in identifying the SOTA and finding key gaps in AI algorithms and develop a world leading AI algorithms for optimizing real-time Ad Serving engine. Identify and optimize the core modules such as Traffic Prediction, Optimization, Ad Targeting/Re-targeting, Ad Performance Optimization, Audience insights, Attribution, Bidding, re-ranking, and Diagnostics. Support hundreds of billions of ad requests per day, with efficiently cache technology.\\nTo build and enhance Ad platform features and Prediction capabilities in Huawei Ads Platform\\nOptimized Cost Per Mille; Optimized Cost Per Action; Optimized Cost Per Click and Cost per Click. OCPM, OCPA, OCPC.\\n\\nRequirements:\\n- Strong hands-on experience in implementing and validating big data algorithms and models including Deep Learning models like Seq2Seq/ GRU/RNN/LSTM , Knowledge Graph, Massive Graph algorithms, etc.\\n- Programming experience with Python\\n- Able to validate existing models including Deep Learning models with large scale dataset and able to make changes to the models to achieve better performance\\n- AdServing domain Experience is an added advantage\\nRoleAnalytics Manager\\nIndustry TypeTelecom / ISP\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Any Postgraduate in Any Specialization\\nKey Skills\\nRnnAlgorithmsLstmArtificial IntelligenceData ScientistBig DataData MiningStatistical AnalysisDeep LearningPython',\n",
       " 'Job description\\nBusiness & Team overview:\\nFounded in 1987, Huawei is a leading global provider of ICT (information and communications technology) infrastructure and smart devices. We are committed to bringing digital to every person, home and organization for a fully connected, intelligent world. We have nearly 194,000 employees, and we operate in more than 170 countries and regions, serving more than 3 billion people around the world.\\n\\nHuawei Technologies has three business directions: Carrier Business Group, which provides innovative and secure network equipment to telecom carriers, including the leading 5G mobile network.\\nEnterprise Business Group, which provides facilities and solutions to big and small companies, including IT facilities.\\nConsumer Business Groups, which provides devices to the customer, including mobile phones, PC, tablet, TV, audio, glasses, watches, locomotives, and headphones. And also provide solutions on mobile offices, smart homes, sports and health, audio-visual entertainment, and smart travel products.\\n\\nThis opportunity is belong to Huawei Consumer Business Group.\\n\\nDriven by the coordinated development of \"Chip-Device-Cloud\", consumer products such as smartphones are becoming increasingly intelligent and pervasive. The era of smart services is the future.\\nHuawei Ads Services is dedicated to provide Huawei end-users with high-quality digital experiences, to build a business closed-loop system for Developers and Improve the ROI for the Advertisers\\n.\\nIn 2020 Q1, along with more than 650 million users and 1,400,000 registered developers worldwide, we have the following unique advantages:\\n1. With All-scenario intelligent solution, the Huawei devices become super entrance of traffic, including mobile phones, PC, tablet, TV, audio, glasses, watches, locomotives, and head phones\\n2. This team will be responsible for building a new Ad Serving Platform and have the opportunity to define the product for our Huawei end-users.\\n3. AI-Driven is the direction of Ads, Huawei is going to build a strong team in India to Innovate and deliver AI-driven Smart Ad Serving Platforms\\n\\n1. Job Title: Computational Design Lead Data Scientist\\n\\nResponsibility:\\nTake-up Key creative tools of the creative platform for Advertisers, research and develop breakthrough CNN based deep learning algorithms to solve the problem unique in the industry and productionize the algorithms, measure the ad creative performance and enhance the algorithm to ease the Ad Designer job.\\nDevelop the common AI platforms and frameworks to ease the experimentation of the Algorithms for creative Design.\\nTo build ability to understand the advertisers intent and provide creative assistance every step of creating all types of adverts\\nResponsible for intelligent identification of advertising creatives (pictures, videos) and related algorithms of content understanding.\\nResponsible for Image Synthesis, Intelligent Layout, Style Transfer, and other image processing, computing and visual processing, to improve the aesthetic level of advertising creativity.\\nResponsible for designing algorithms for suggesting how to intelligently crop and position an image for maximum effect, identify the optimal placement of text and copywriting.\\nResponsible for the algorithm and model of dynamic matching of advertising program creativity and dynamic creation of advertising content\\n\\nRequirements:\\nDeep knowledge of Computational Design\\nExperience on Intelligent composition, including image cropping, smart layout, the Gold Ratio composition, visual extension.\\nExperience computer vision models, including image/video recognition and content understanding.\\nExperience in algorithms such as image and video segmentation, separation, synthesis, and intelligent layout with engineering platform implementation capability.\\nStrong Knowledge Algorithms such as Image segmentation, object detection, Image processing (filtering, noise removal, histogram thresholding, etc.), object tracking, image transformation (affine transform, dewarping), keypoint detection/description, etc (and experience in using Computer vision Libraries)\\nStrong Knowledge in CNN, R-CNN, GAN, LSTM, GRU, Multimodal feature Learning, ASR, NLU, NLG, Copywriting and KG will be an added advantage\\nStrong logic/probability thinking ability and be good at analyzing, summarizing, describing, communicating, and solving problems\\nWorking experience in related online advertising products/creative platform is preferred\\nWorking experience in Computer Vision (CV) to enhance user artistic creativity while creating creatives/adverts is preferred\\nAbility to identify trends of advertising creative platform.\\n\\n\\nRoleData Analyst\\nIndustry TypeTelecom / ISP\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Any Postgraduate in Any Specialization\\nKey Skills\\nObject DetectionR-CNNCnnAlgorithmsLstmGANArtificial IntelligenceImage ProcessingData ScientistComputer VisionComputational DesignDeep Learning',\n",
       " 'Job description\\nDear Aspirant,\\n\\nGreetings from Globaledx\\n\\nRoles and Responsibilities\\n\\nExperience : 3+ Years\\nCTC : Best in Market\\nLocation : Pan India\\nContract Period : 3-6 Months\\nSkill : Python, NLP, Machine Learning Models, Data Scientist\\n\\nInterested, please share your updated resume to hr@globaledx.com\\nOr Call /Whatsapp at Sowjanya : 9505072408\\n\\nPlease share with your friends for more reach!\\nRoleIT/Technical Content Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryOther\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nPostgresqlDATA SCIENTISTMachine LearningScikit-LearnsqlpandasNLPoptimal codingRundeckmachine learning modelslogging frameworkshtmlNUMPYPython',\n",
       " 'Job description\\nAbout the Role\\nFasten your helmet and climb on board if youre ready to be our Senior Data Scientist. In this role, youll be a key leader within the Customer Platform group, mining insights from the sea of data, building data products, and designing experiments with the ability to see the real-time impact of your contribution. A talented troop of business leads and fellow analysts will be your companions on this ride. In our humble opinion, the coolest part of this role is how your work will directly impact how the senior leaders at Gojek shape strategies around millions of customers across Southeast Asia.\\nWhat You Will Do\\nBuild machine learning models that generate or foster answers to some of the most complex technical issues presented\\nProductionize models that deliver a personalized experience via recommendation and customer behavioral modeling\\nOwn Data Science projects from inception to deployment, utilizing our own internal tools throughout every stage\\nBe a technical leader within the Consumer Platform team, supporting others and enabling them to perform at their best ability\\nAlong with Product Managers, own the business outcomes/metrics driven by the data science model/algorithm\\nWhat You Will Need\\nAt least 5 years of practical experience using Python, Shell scripting, and SQL, with a focus on driving key business metrics\\nPrior experience with Applied Statistics, Experimental Design, Machine Learning and Git version control\\nExperience with experimenting on different modeling techniques (supervised and unsupervised learning) and developing data visualization for data stories\\nExperience in bringing models to production and delivering models via API and CI/CD\\nStrong ability to recognize business needs, and collaborate with multiple stakeholders of all levels from the Business and Operations teams, as well as PMs\\nAbility to work equally well independently and within a group in an interdisciplinary team environment\\nRoleTeam Lead/Technical Lead\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - eCommerce, Internet Technologies\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Post Graduation Not Required\\nKey Skills\\nMiningVersion controlGITdata scienceAnalyticalShell scriptingMachine learningdata visualizationSQLPython']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Finding length of job_title, company_name, experience_list and location_list\n",
    "print(len(job_titles),len(company_names),len(Job_description),len(location_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataframe\n",
    "job1=pd.DataFrame({})\n",
    "job1['title']=job_titles\n",
    "job1['company']=company_names\n",
    "job1['description']=Job_description\n",
    "job1['location']=location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Job description\\nJob Role : Data Scientist/Dat...</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>Job description\\nRole: Data Scientist\\n\\nRoles...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Chennai, Bang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data - Data Scientist</td>\n",
       "      <td>Xoriant Solutions Pvt Ltd</td>\n",
       "      <td>-</td>\n",
       "      <td>Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specialist I - Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Job description\\nResponsibilities and Key Resu...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>-</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>-</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SDE Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>Job description\\nBusiness &amp; Team overview:\\nFo...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Computational Design Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>Job description\\nBusiness &amp; Team overview:\\nFo...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For DATA Scientist - ON Contract Basis ...</td>\n",
       "      <td>GlobalEdx Learning and Technology Solution Pvt...</td>\n",
       "      <td>Job description\\nDear Aspirant,\\n\\nGreetings f...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>GO-JEK India</td>\n",
       "      <td>Job description\\nAbout the Role\\nFasten your h...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                     Data Scientist   \n",
       "2                          Big Data - Data Scientist   \n",
       "3                      Specialist I - Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                         SDE Lead Data Scientist-L3   \n",
       "7        Computational Design Lead Data Scientist-L3   \n",
       "8  Hiring For DATA Scientist - ON Contract Basis ...   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                             company  \\\n",
       "0                 Inflexion Analytix Private Limited   \n",
       "1                                      Wipro Limited   \n",
       "2                          Xoriant Solutions Pvt Ltd   \n",
       "3                              Philips India Limited   \n",
       "4                             IBM India Pvt. Limited   \n",
       "5                             Oracle India Pvt. Ltd.   \n",
       "6                  Huawei Technologies India Pvt Ltd   \n",
       "7                  Huawei Technologies India Pvt Ltd   \n",
       "8  GlobalEdx Learning and Technology Solution Pvt...   \n",
       "9                                       GO-JEK India   \n",
       "\n",
       "                                         description  \\\n",
       "0  Job description\\nJob Role : Data Scientist/Dat...   \n",
       "1  Job description\\nRole: Data Scientist\\n\\nRoles...   \n",
       "2                                                  -   \n",
       "3  Job description\\nResponsibilities and Key Resu...   \n",
       "4                                                  -   \n",
       "5                                                  -   \n",
       "6  Job description\\nBusiness & Team overview:\\nFo...   \n",
       "7  Job description\\nBusiness & Team overview:\\nFo...   \n",
       "8  Job description\\nDear Aspirant,\\n\\nGreetings f...   \n",
       "9  Job description\\nAbout the Role\\nFasten your h...   \n",
       "\n",
       "                                            location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1  Kolkata, Hyderabad/Secunderabad, Chennai, Bang...  \n",
       "2  Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results on naukri portal.\n",
    "\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "\n",
    "The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com'\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding elements for job search bar and writing the required job.\n",
    "search_job= driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click on xpath function\n",
    "search_btn= driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering location to Delhi/NCR\n",
    "loc=driver.find_element_by_xpath(\"//span[@title='Delhi / NCR']\")\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering salary to 3-6 Lakhs\n",
    "salary=driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having job titles\n",
    "titles_tag3=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Business Analyst- Data Scientist',\n",
       " 'Data Scientist - High growth VC backed Influencer Marketplace',\n",
       " 'DATA Scientist – Gurgaon (Exp 3-6 years)',\n",
       " 'DATA Scientist – Gurgaon (Exp 3-6 years)',\n",
       " 'Data Scientist - Noida',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist II 5+ yrs II Gurgaon']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles3=[]\n",
    "for i in titles_tag3:\n",
    "    job_titles3.append(i.text)\n",
    "job_titles3=job_titles3[:10]\n",
    "job_titles3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having company name\n",
    "companies_tags3=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Wipro',\n",
       " 'Ravgins International Pvt. Ltd.',\n",
       " 'CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVATE L IMITED',\n",
       " 'CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVATE L IMITED',\n",
       " 'Optum Global Solutions (India) Private Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Blitz Jobs',\n",
       " 'Country Veggie',\n",
       " 'Zenatix Solutions Private Limited']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_names3=[]\n",
    "for i in companies_tags3:\n",
    "    company_names3.append(i.text)\n",
    "company_names3=company_names3[:10]\n",
    "company_names3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having location\n",
    "locations_tags3=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Noida, Gurgaon/Gurugram',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Noida',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Noida',\n",
       " 'Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpur, Ghaziabad, Jaunpur, Kanpur, New Delhi, Lucknow, Agra, Gurgaon/Gurugram, Rajkot, Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_list3=[]\n",
    "for i in locations_tags3:\n",
    "    location_list3.append(i.text)\n",
    "location_list3=location_list3[:10]\n",
    "location_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having experience\n",
    "experience_tags3=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-5 Yrs',\n",
       " '3-6 Yrs',\n",
       " '3-6 Yrs',\n",
       " '3-5 Yrs',\n",
       " '4-9 Yrs',\n",
       " '3-5 Yrs',\n",
       " '1-3 Yrs',\n",
       " '5-10 Yrs']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience_list3=[]\n",
    "for i in experience_tags3:\n",
    "    experience_list3.append(i.text)\n",
    "experience_list3=experience_list3[:10]\n",
    "experience_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Finding length of job_title, company_name, experience_list and location_list\n",
    "print(len(job_titles),len(company_names),len(experience_list3),len(location_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Dataframe\n",
    "job2=pd.DataFrame({})\n",
    "job2['title']=job_titles\n",
    "job2['company']=company_names\n",
    "job2['experience']=experience_list3\n",
    "job2['location']=location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Chennai, Bang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data - Data Scientist</td>\n",
       "      <td>Xoriant Solutions Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specialist I - Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SDE Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Computational Design Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For DATA Scientist - ON Contract Basis ...</td>\n",
       "      <td>GlobalEdx Learning and Technology Solution Pvt...</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>GO-JEK India</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                     Data Scientist   \n",
       "2                          Big Data - Data Scientist   \n",
       "3                      Specialist I - Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                         SDE Lead Data Scientist-L3   \n",
       "7        Computational Design Lead Data Scientist-L3   \n",
       "8  Hiring For DATA Scientist - ON Contract Basis ...   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                             company experience  \\\n",
       "0                 Inflexion Analytix Private Limited    0-3 Yrs   \n",
       "1                                      Wipro Limited    2-5 Yrs   \n",
       "2                          Xoriant Solutions Pvt Ltd    3-5 Yrs   \n",
       "3                              Philips India Limited    3-6 Yrs   \n",
       "4                             IBM India Pvt. Limited    3-6 Yrs   \n",
       "5                             Oracle India Pvt. Ltd.    3-5 Yrs   \n",
       "6                  Huawei Technologies India Pvt Ltd    4-9 Yrs   \n",
       "7                  Huawei Technologies India Pvt Ltd    3-5 Yrs   \n",
       "8  GlobalEdx Learning and Technology Solution Pvt...    1-3 Yrs   \n",
       "9                                       GO-JEK India   5-10 Yrs   \n",
       "\n",
       "                                            location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1  Kolkata, Hyderabad/Secunderabad, Chennai, Bang...  \n",
       "2  Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for first 10 job on glassdoor portal, results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2='https://www.glassdoor.co.in/index.htm'\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding element for job search bar\n",
    "search2job= driver.find_element_by_id(\"sc.keyword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing on search bar\n",
    "search2job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding element for job location bar\n",
    "search2loc=driver.find_element_by_id(\"sc.location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing on location bar\n",
    "search2loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click using xpath function\n",
    "search2btn= driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search2btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having job title\n",
    "titles_tag4=driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Applied Materials Inc.',\n",
       " 'Wells Fargo',\n",
       " 'CoStrategix',\n",
       " 'Truecaller',\n",
       " 'Koch Business Solutions India',\n",
       " 'Virtusa',\n",
       " 'People Interactive Pvt Ltd.',\n",
       " 'Walmart Global Tech India',\n",
       " 'Adobe',\n",
       " 'Hewlett Packard Enterprise']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles4=[]\n",
    "for i in titles_tag4:\n",
    "    job_titles4.append(i.text)\n",
    "job_titles4=job_titles4[:10]\n",
    "job_titles4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having post time\n",
    "post_ago=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9d', '24d', '15d', '4d', '', '5d', '12d', '15d', '1d', '9d']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_time=[]\n",
    "for i in post_ago:\n",
    "    post_time.append(i.text)\n",
    "post_time=post_time[:10]\n",
    "post_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "post=driver.find_elements_by_xpath(\"//div[@class='d-flex flex-column pl-sm css-1d3xmk8 e1rrn5ka4']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having rating\n",
    "rating=[]\n",
    "for i in post:\n",
    "    i.click()\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        ratings=driver.find_element_by_xpath(\"//div[@class='mr-sm css-ey2fjr e1pr2f4f2']\")\n",
    "        rating.append(ratings.text)\n",
    "    except NoSuchElementException:\n",
    "        rating.append('-')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.3', '4.3', '4.3', '4.3', '4.3', '4.3', '4.3', '4.3', '4.3', '4.3']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=rating[:10]\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Finding length of job_title, post time and rating\n",
    "print(len(job_titles4),len(post_time),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataframe\n",
    "job3=pd.DataFrame({})\n",
    "job3['title']=job_titles4\n",
    "job3['upload_time']=post_time\n",
    "job3['rating']=rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Applied Materials Inc.</td>\n",
       "      <td>9d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>24d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CoStrategix</td>\n",
       "      <td>15d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Truecaller</td>\n",
       "      <td>4d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Koch Business Solutions India</td>\n",
       "      <td></td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Virtusa</td>\n",
       "      <td>5d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>People Interactive Pvt Ltd.</td>\n",
       "      <td>12d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Walmart Global Tech India</td>\n",
       "      <td>15d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>1d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>9d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title upload_time rating\n",
       "0         Applied Materials Inc.          9d    4.3\n",
       "1                    Wells Fargo         24d    4.3\n",
       "2                    CoStrategix         15d    4.3\n",
       "3                     Truecaller          4d    4.3\n",
       "4  Koch Business Solutions India                4.3\n",
       "5                        Virtusa          5d    4.3\n",
       "6    People Interactive Pvt Ltd.         12d    4.3\n",
       "7      Walmart Global Tech India         15d    4.3\n",
       "8                          Adobe          1d    4.3\n",
       "9     Hewlett Packard Enterprise          9d    4.3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape the salary data for Data Scientist designation in Noida location on glassdoor portal.\n",
    "\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3='https://www.glassdoor.co.in/Salaries/index.htm'\n",
    "driver.get(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding element for job search bar\n",
    "search3job= driver.find_element_by_id(\"KeywordSearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing on search bar\n",
    "search3job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding element for job location bar\n",
    "search3loc=driver.find_element_by_id(\"LocationSearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing on location bar\n",
    "search3loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click using xpath function\n",
    "search3btn= driver.find_element_by_id(\"HeroSearchButton\")\n",
    "search3btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having company name\n",
    "company=driver.find_elements_by_xpath(\"//p[@class='m-0 ']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tata Consultancy Services',\n",
       " 'Accenture',\n",
       " 'IBM',\n",
       " 'Ericsson-Worldwide',\n",
       " 'Delhivery',\n",
       " 'UnitedHealth Group',\n",
       " 'Valiance Solutions',\n",
       " 'ZS Associates',\n",
       " 'EXL Service',\n",
       " 'Optum Global Solutions']"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name=[]\n",
    "for i in company:\n",
    "    company_name.append(i.text)\n",
    "company_name=company_name[:10]\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having number of salary\n",
    "salary=driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16 salaries',\n",
       " '14 salaries',\n",
       " '14 salaries',\n",
       " '14 salaries',\n",
       " '14 salaries',\n",
       " '11 salaries',\n",
       " '9 salaries',\n",
       " '8 salaries',\n",
       " '8 salaries',\n",
       " '8 salaries']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_num=[]\n",
    "for i in salary:\n",
    "    salary_num.append(i.text)\n",
    "salary_num=salary_num[:10]\n",
    "salary_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having average salary\n",
    "average=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 6,11,228/yr',\n",
       " '₹ 11,46,533/yr',\n",
       " '₹ 8,97,795/yr',\n",
       " '₹ 7,38,057/yr',\n",
       " '₹ 12,39,781/yr',\n",
       " '₹ 13,36,142/yr',\n",
       " '₹ 8,15,192/yr',\n",
       " '₹ 11,35,221/yr',\n",
       " '₹ 11,44,243/yr',\n",
       " '₹ 14,13,288/yr']"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_avg=[]\n",
    "for i in average:\n",
    "    salary_avg.append(i.text.replace('\\n',''))\n",
    "salary_avg=salary_avg[:10]\n",
    "salary_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having minimum salary\n",
    "minmum=driver.find_elements_by_xpath(\"//span[@class=''][1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Very High\\nConfidence',\n",
       " 'Updated 18 May 2021',\n",
       " '',\n",
       " '₹343K',\n",
       " '₹577K',\n",
       " '₹586K',\n",
       " '₹355K',\n",
       " '₹450K',\n",
       " '₹1,069K',\n",
       " '₹502K',\n",
       " '₹202K',\n",
       " '₹575K',\n",
       " '₹1,014K',\n",
       " '₹620K',\n",
       " '₹792K',\n",
       " '₹807K',\n",
       " '₹405K',\n",
       " '₹971K',\n",
       " '₹400K',\n",
       " '₹817K',\n",
       " '₹12K',\n",
       " '₹86K',\n",
       " '₹772K']"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_min=[]\n",
    "for i in minmum:\n",
    "    salary_min.append(i.text)\n",
    "salary_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹343K',\n",
       " '₹577K',\n",
       " '₹586K',\n",
       " '₹355K',\n",
       " '₹450K',\n",
       " '₹1,069K',\n",
       " '₹502K',\n",
       " '₹202K',\n",
       " '₹575K',\n",
       " '₹1,014K']"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_min=salary_min[4:14:]\n",
    "salary_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having maximum salary\n",
    "maximum=driver.find_elements_by_xpath(\"//span[@class=''][2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹1,095K',\n",
       " '₹2,213K',\n",
       " '₹2,730K',\n",
       " '₹1,613K',\n",
       " '₹11,622K',\n",
       " '₹1,520K',\n",
       " '₹1,465K',\n",
       " '₹1,809K',\n",
       " '₹1,520K',\n",
       " '₹2,149K']"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_max=[]\n",
    "for i in maximum:\n",
    "    salary_max.append(i.text)\n",
    "salary_max=salary_max[:10]\n",
    "salary_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Finding length of company name, number of salary, average salary, minimum salary, maximum salary\n",
    "print(len(company_name),len(salary_num),len(salary_avg),len(salary_min),len(salary_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe\n",
    "job4=pd.DataFrame({})\n",
    "job4['company']=company_name\n",
    "job4['salary_num']=salary_num\n",
    "job4['salary_avg']=salary_avg\n",
    "job4['salary_min']=salary_min\n",
    "job4['salary_max']=salary_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>salary_num</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>16 salaries</td>\n",
       "      <td>₹ 6,11,228/yr</td>\n",
       "      <td>₹343K</td>\n",
       "      <td>₹1,095K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 11,46,533/yr</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,213K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 8,97,795/yr</td>\n",
       "      <td>₹586K</td>\n",
       "      <td>₹2,730K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 7,38,057/yr</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹1,613K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 12,39,781/yr</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,622K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹ 13,36,142/yr</td>\n",
       "      <td>₹1,069K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 8,15,192/yr</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,465K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,35,221/yr</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>₹1,809K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,44,243/yr</td>\n",
       "      <td>₹575K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 14,13,288/yr</td>\n",
       "      <td>₹1,014K</td>\n",
       "      <td>₹2,149K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company   salary_num      salary_avg salary_min  \\\n",
       "0  Tata Consultancy Services  16 salaries   ₹ 6,11,228/yr      ₹343K   \n",
       "1                  Accenture  14 salaries  ₹ 11,46,533/yr      ₹577K   \n",
       "2                        IBM  14 salaries   ₹ 8,97,795/yr      ₹586K   \n",
       "3         Ericsson-Worldwide  14 salaries   ₹ 7,38,057/yr      ₹355K   \n",
       "4                  Delhivery  14 salaries  ₹ 12,39,781/yr      ₹450K   \n",
       "5         UnitedHealth Group  11 salaries  ₹ 13,36,142/yr    ₹1,069K   \n",
       "6         Valiance Solutions   9 salaries   ₹ 8,15,192/yr      ₹502K   \n",
       "7              ZS Associates   8 salaries  ₹ 11,35,221/yr      ₹202K   \n",
       "8                EXL Service   8 salaries  ₹ 11,44,243/yr      ₹575K   \n",
       "9     Optum Global Solutions   8 salaries  ₹ 14,13,288/yr    ₹1,014K   \n",
       "\n",
       "  salary_max  \n",
       "0    ₹1,095K  \n",
       "1    ₹2,213K  \n",
       "2    ₹2,730K  \n",
       "3    ₹1,613K  \n",
       "4   ₹11,622K  \n",
       "5    ₹1,520K  \n",
       "6    ₹1,465K  \n",
       "7    ₹1,809K  \n",
       "8    ₹1,520K  \n",
       "9    ₹2,149K  "
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4='https://www.flipkart.com/'\n",
    "driver.get(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locating search bar\n",
    "search4job= driver.find_element_by_xpath(\"//input[@class='_3704LK']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing o search bar\n",
    "search4job.send_keys(\"Sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do click using xpath function\n",
    "search4btn= driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search4btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching URL\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list=[]\n",
    "product_desc=[]\n",
    "price_list=[]\n",
    "discount_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all required tags\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        brand=driver.find_element_by_xpath(\"//span[@class='G6XhRU']\")\n",
    "        brand_list.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_list.append('-')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@class='col col-11-12 _2cLjiM']\").click()\n",
    "        desc=driver.find_element_by_xpath(\"//div[@class='X3BRps _13swYk']\")\n",
    "        product_desc.append(desc.text.replace('\\n',''))\n",
    "    except NoSuchElementException:\n",
    "        product_desc.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        price=driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        price_list.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        price_list.append('-')  \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        discount=driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount_list.append(discount.text)\n",
    "    except NoSuchElementException:\n",
    "        discount_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 38 38 38\n"
     ]
    }
   ],
   "source": [
    "# Finding length of brand list, product description, price list, discount list of page 1\n",
    "print(len(brand_list),len(product_desc),len(price_list),len(discount_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on flipkart tag on above, then find search bar, write on search bar and do click\n",
    "driver.find_element_by_xpath(\"//img[@class='_2xm1JU']\").click()\n",
    "search4job= driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search4job.send_keys(\"Sunglasses\")\n",
    "search4btn= driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search4btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click on next button\n",
    "btn= driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching on URL\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list2=[]\n",
    "product_desc2=[]\n",
    "price_list2=[]\n",
    "discount_list2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all required tags\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        brand=driver.find_element_by_xpath(\"//span[@class='G6XhRU']\")\n",
    "        brand_list2.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_list2.append('-')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@class='col col-11-12 _2cLjiM']\").click()\n",
    "        desc=driver.find_element_by_xpath(\"//div[@class='X3BRps _13swYk']\")\n",
    "        product_desc2.append(desc.text.replace('\\n',''))\n",
    "    except NoSuchElementException:\n",
    "        product_desc2.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        price=driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        price_list2.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        price_list2.append('-')  \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        discount=driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount_list2.append(discount.text)\n",
    "    except NoSuchElementException:\n",
    "        discount_list2.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 40\n"
     ]
    }
   ],
   "source": [
    "# Finding length of brand list, product description, price list, discount list of page 2\n",
    "print(len(brand_list2),len(product_desc2),len(price_list2),len(discount_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on flipkart tag on above, then find search bar, write on search bar and do click\n",
    "driver.find_element_by_xpath(\"//img[@class='_2xm1JU']\").click()\n",
    "search4job= driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search4job.send_keys(\"Sunglasses\")\n",
    "search4btn= driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search4btn.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click on next button\n",
    "btn= driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click on next button again\n",
    "btn2= driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "btn2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching on URL\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list3=[]\n",
    "product_desc3=[]\n",
    "price_list3=[]\n",
    "discount_list3=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all required tags\n",
    "for i in urls[:22]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        brand=driver.find_element_by_xpath(\"//span[@class='G6XhRU']\")\n",
    "        brand_list3.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_list3.append('-')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@class='col col-11-12 _2cLjiM']\").click()\n",
    "        desc=driver.find_element_by_xpath(\"//div[@class='X3BRps _13swYk']\")\n",
    "        product_desc3.append(desc.text.replace('\\n',''))\n",
    "    except NoSuchElementException:\n",
    "        product_desc3.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        price=driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        price_list3.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        price_list3.append('-')  \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        discount=driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount_list3.append(discount.text)\n",
    "    except NoSuchElementException:\n",
    "        discount_list3.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 22 22 22\n"
     ]
    }
   ],
   "source": [
    "# Finding length of brand list, product description, price list, discount list of page 3\n",
    "print(len(brand_list3),len(product_desc3),len(price_list3),len(discount_list3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging page 1 2 3 data.\n",
    "brand=brand_list+brand_list2+brand_list3\n",
    "product_desc=product_desc+product_desc2+product_desc3\n",
    "price=price_list+price_list2+price_list3\n",
    "discount=discount_list+discount_list2+discount_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "# Finding length of brand list, product description, price list, discount list\n",
    "print(len(brand),len(product_desc),len(price),len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe\n",
    "job5=pd.DataFrame({})\n",
    "job5['brand']=brand\n",
    "job5['product_desc']=product_desc\n",
    "job5['price']=price\n",
    "job5['discount']=discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_desc</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>SizeThis product is sold as Medium by the Bran...</td>\n",
       "      <td>₹195</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>SizeThis product is sold as Free Size by the B...</td>\n",
       "      <td>₹570</td>\n",
       "      <td>28% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>SizeThis product is sold as Free Size by the B...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>SizeThis product is sold as Free Size by the B...</td>\n",
       "      <td>₹733</td>\n",
       "      <td>18% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>SizeThis product is sold as Free Size by the B...</td>\n",
       "      <td>₹404</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Flizz</td>\n",
       "      <td>SizeThis product is sold as Free Size by the B...</td>\n",
       "      <td>₹279</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>SizeThis product is sold as Large by the Brand...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>SizeThis product is sold as Large by the Brand...</td>\n",
       "      <td>₹1,100</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>hipe</td>\n",
       "      <td>SizeThis product is sold as Free Size by the B...</td>\n",
       "      <td>₹219</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>SizeThis product is sold as Medium by the Bran...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              brand                                       product_desc  \\\n",
       "0            NuVew   SizeThis product is sold as Medium by the Bran...   \n",
       "1         Fastrack   SizeThis product is sold as Free Size by the B...   \n",
       "2   ROZZETTA CRAFT   SizeThis product is sold as Free Size by the B...   \n",
       "3         Fastrack   SizeThis product is sold as Free Size by the B...   \n",
       "4   ROZZETTA CRAFT   SizeThis product is sold as Free Size by the B...   \n",
       "..              ...                                                ...   \n",
       "95           Flizz   SizeThis product is sold as Free Size by the B...   \n",
       "96  ROZZETTA CRAFT   SizeThis product is sold as Large by the Brand...   \n",
       "97          AISLIN   SizeThis product is sold as Large by the Brand...   \n",
       "98            hipe   SizeThis product is sold as Free Size by the B...   \n",
       "99       ROYAL SON   SizeThis product is sold as Medium by the Bran...   \n",
       "\n",
       "     price discount  \n",
       "0     ₹195  75% off  \n",
       "1     ₹570  28% off  \n",
       "2     ₹499  77% off  \n",
       "3     ₹733  18% off  \n",
       "4     ₹404  79% off  \n",
       "..     ...      ...  \n",
       "95    ₹279  81% off  \n",
       "96    ₹499  75% off  \n",
       "97  ₹1,100  72% off  \n",
       "98    ₹219  83% off  \n",
       "99    ₹499  66% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "\n",
    "You have to scrape three attributes:\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "url5='https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace'\n",
    "driver.get(url5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do click to more reviews\n",
    "driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# So lets extract all tags having star rating, shot_review, full_review of 1st page\n",
    "rating=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "star_rating=[]\n",
    "for i in rating:\n",
    "    star_rating.append(i.text)\n",
    "star_rating\n",
    "\n",
    "sreview=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "short_review=[]\n",
    "for i in sreview:\n",
    "    short_review.append(i.text)\n",
    "short_review\n",
    "\n",
    "\n",
    "freview=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "full_review=[]\n",
    "for i in freview:\n",
    "    full_review.append(i.text.replace('\\n',''))\n",
    "    \n",
    "print(len(star_rating),len(short_review),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do click on next page.\n",
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# So lets extract all tags having star rating, shot_review, full_review of 2nd page\n",
    "rating=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "star_rating2=[]\n",
    "for i in rating:\n",
    "    star_rating2.append(i.text)\n",
    "star_rating2\n",
    "\n",
    "sreview=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "short_review2=[]\n",
    "for i in sreview:\n",
    "    short_review2.append(i.text)\n",
    "short_review2\n",
    "\n",
    "\n",
    "freview=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "full_review2=[]\n",
    "for i in freview:\n",
    "    full_review2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "print(len(star_rating2),len(short_review2),len(full_review2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# So lets extract all tags having star rating, shot_review, full_review of 3rd page\n",
    "rating=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "star_rating3=[]\n",
    "for i in rating:\n",
    "    star_rating3.append(i.text)\n",
    "star_rating3\n",
    "\n",
    "sreview=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "short_review3=[]\n",
    "for i in sreview:\n",
    "    short_review3.append(i.text)\n",
    "short_review3\n",
    "\n",
    "\n",
    "freview=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "full_review3=[]\n",
    "for i in freview:\n",
    "    full_review3.append(i.text.replace('\\n',''))\n",
    "    \n",
    "print(len(star_rating3),len(short_review3),len(full_review3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# So lets extract all tags having star rating, shot_review, full_review of 4th page\n",
    "rating=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "star_rating4=[]\n",
    "for i in rating:\n",
    "    star_rating4.append(i.text)\n",
    "star_rating4\n",
    "\n",
    "sreview=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "short_review4=[]\n",
    "for i in sreview:\n",
    "    short_review4.append(i.text)\n",
    "short_review4\n",
    "\n",
    "\n",
    "freview=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "full_review4=[]\n",
    "for i in freview:\n",
    "    full_review4.append(i.text.replace('\\n',''))\n",
    "    \n",
    "print(len(star_rating4),len(short_review4),len(full_review4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# So lets extract all tags having star rating, shot_review, full_review of 5th page\n",
    "rating=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "star_rating5=[]\n",
    "for i in rating:\n",
    "    star_rating5.append(i.text)\n",
    "star_rating5\n",
    "\n",
    "sreview=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "short_review5=[]\n",
    "for i in sreview:\n",
    "    short_review5.append(i.text)\n",
    "short_review5\n",
    "\n",
    "\n",
    "freview=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "full_review5=[]\n",
    "for i in freview:\n",
    "    full_review5.append(i.text.replace('\\n',''))\n",
    "    \n",
    "print(len(star_rating5),len(short_review5),len(full_review5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# So lets extract all tags having star rating, shot_review, full_review of 6th page\n",
    "rating=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "star_rating6=[]\n",
    "for i in rating:\n",
    "    star_rating6.append(i.text)\n",
    "star_rating6\n",
    "\n",
    "\n",
    "sreview=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "short_review6=[]\n",
    "for i in sreview:\n",
    "    short_review6.append(i.text)\n",
    "short_review6\n",
    "\n",
    "\n",
    "freview=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "full_review6=[]\n",
    "for i in freview:\n",
    "    full_review6.append(i.text.replace('\\n',''))\n",
    "    \n",
    "print(len(star_rating6),len(short_review6),len(full_review6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# So lets extract all tags having star rating, shot_review, full_review of 7th page\n",
    "rating=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "star_rating7=[]\n",
    "for i in rating:\n",
    "    star_rating7.append(i.text)\n",
    "star_rating7\n",
    "\n",
    "sreview=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "short_review7=[]\n",
    "for i in sreview:\n",
    "    short_review7.append(i.text)\n",
    "short_review7\n",
    "\n",
    "\n",
    "freview=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "full_review7=[]\n",
    "for i in freview:\n",
    "    full_review7.append(i.text.replace('\\n',''))\n",
    "    \n",
    "print(len(star_rating7),len(short_review7),len(full_review7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# So lets extract all tags having star rating, shot_review, full_review of 8th page\n",
    "rating=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "star_rating8=[]\n",
    "for i in rating:\n",
    "    star_rating8.append(i.text)\n",
    "star_rating8\n",
    "\n",
    "sreview=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "short_review8=[]\n",
    "for i in sreview:\n",
    "    short_review8.append(i.text)\n",
    "short_review8\n",
    "\n",
    "\n",
    "freview=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "full_review8=[]\n",
    "for i in freview:\n",
    "    full_review8.append(i.text.replace('\\n',''))\n",
    "    \n",
    "print(len(star_rating8),len(short_review8),len(full_review8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# So lets extract all tags having star rating, shot_review, full_review of 9th page\n",
    "rating=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "star_rating9=[]\n",
    "for i in rating:\n",
    "    star_rating9.append(i.text)\n",
    "star_rating9\n",
    "\n",
    "sreview=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "short_review9=[]\n",
    "for i in sreview:\n",
    "    short_review9.append(i.text)\n",
    "short_review9\n",
    "\n",
    "\n",
    "freview=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "full_review9=[]\n",
    "for i in freview:\n",
    "    full_review9.append(i.text.replace('\\n',''))\n",
    "    \n",
    "print(len(star_rating9),len(short_review9),len(full_review9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# So lets extract all tags having star rating, shot_review, full_review of 10th page\n",
    "rating=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "star_rating10=[]\n",
    "for i in rating:\n",
    "    star_rating10.append(i.text)\n",
    "star_rating10\n",
    "\n",
    "sreview=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "short_review10=[]\n",
    "for i in sreview:\n",
    "    short_review10.append(i.text)\n",
    "short_review10\n",
    "\n",
    "\n",
    "freview=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "full_review10=[]\n",
    "for i in freview:\n",
    "    full_review10.append(i.text.replace('\\n',''))\n",
    "    \n",
    "print(len(star_rating10),len(short_review10),len(full_review10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging 1 to 10 page data into one variable\n",
    "star_rating=star_rating+star_rating2+star_rating3+star_rating4+star_rating5+star_rating6+star_rating7+star_rating8+star_rating9+star_rating10\n",
    "short_review=short_review+short_review2+short_review3+short_review4+short_review5+short_review6+short_review7+short_review8+short_review9+short_review10\n",
    "full_review=full_review+full_review2+full_review3+full_review4+full_review5+full_review6+full_review7+full_review8+full_review9+full_review10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "# Finding length of star_rating, short_review, full_review.\n",
    "print(len(star_rating),len(short_review),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataframe\n",
    "job6=pd.DataFrame({})\n",
    "job6['rating']=star_rating\n",
    "job6['short_review']=short_review\n",
    "job6['full_review']=full_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>short_review</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the MoneyThe iPhone 11 offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.I’m am ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Seller - SuperComNet ( my trust in you has gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Well , as we all know if its not an Iphone , i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Just an awesome phone...upgraded from 6s to 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>As usual a great product from Apple. but the l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating       short_review  \\\n",
       "0       5          Brilliant   \n",
       "1       5   Perfect product!   \n",
       "2       5      Great product   \n",
       "3       5  Worth every penny   \n",
       "4       4        Good choice   \n",
       "..    ...                ...   \n",
       "95      5          Excellent   \n",
       "96      5  Terrific purchase   \n",
       "97      5          Wonderful   \n",
       "98      5          Fabulous!   \n",
       "99      4    Value-for-money   \n",
       "\n",
       "                                          full_review  \n",
       "0   The Best Phone for the MoneyThe iPhone 11 offe...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.I’m am ver...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   So far it’s been an AMAZING experience coming ...  \n",
       "..                                                ...  \n",
       "95  Seller - SuperComNet ( my trust in you has gro...  \n",
       "96  Well , as we all know if its not an Iphone , i...  \n",
       "97  Nice value for money good and best price I pho...  \n",
       "98  Just an awesome phone...upgraded from 6s to 11...  \n",
       "99  As usual a great product from Apple. but the l...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4='https://www.flipkart.com/'\n",
    "driver.get(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding element for job search bar\n",
    "search4job= driver.find_element_by_xpath(\"//input[@class='_3704LK']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write on search bar\n",
    "search4job.send_keys(\"Sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using xpath function\n",
    "search4btn= driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search4btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching on URL\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list=[]\n",
    "product_desc=[]\n",
    "price_list=[]\n",
    "discount_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all required tags\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        brand=driver.find_element_by_xpath(\"//span[@class='G6XhRU']\")\n",
    "        brand_list.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_list.append('-')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@class='col col-11-12 _2cLjiM']\").click()\n",
    "        desc=driver.find_element_by_xpath(\"//div[@class='X3BRps _13swYk']\")\n",
    "        product_desc.append(desc.text.replace('\\n',''))\n",
    "    except NoSuchElementException:\n",
    "        product_desc.append('-')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        price=driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        price_list.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        price_list.append('-')  \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        discount=driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount_list.append(discount.text)\n",
    "    except NoSuchElementException:\n",
    "        discount_list.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "# Finding length of brand list, product description, price list, discount list of page 1\n",
    "print(len(brand_list),len(product_desc),len(price_list),len(discount_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on flipkart tag on above, then find search bar, write on search bar and do click\n",
    "driver.find_element_by_xpath(\"//img[@class='_2xm1JU']\").click()\n",
    "search4job= driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search4job.send_keys(\"Sneakers\")\n",
    "search4btn= driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search4btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click on next button\n",
    "btn= driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching on URL\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list2=[]\n",
    "product_desc2=[]\n",
    "price_list2=[]\n",
    "discount_list2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all required tags\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        brand=driver.find_element_by_xpath(\"//span[@class='G6XhRU']\")\n",
    "        brand_list2.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_list2.append('-')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@class='col col-11-12 _2cLjiM']\").click()\n",
    "        desc=driver.find_element_by_xpath(\"//div[@class='X3BRps _13swYk']\")\n",
    "        product_desc2.append(desc.text.replace('\\n',''))\n",
    "    except NoSuchElementException:\n",
    "        product_desc2.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        price=driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        price_list2.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        price_list2.append('-')  \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        discount=driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount_list2.append(discount.text)\n",
    "    except NoSuchElementException:\n",
    "        discount_list2.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32 32 32\n"
     ]
    }
   ],
   "source": [
    "# Finding length of brand list, product description, price list, discount list of page 2\n",
    "print(len(brand_list2),len(product_desc2),len(price_list2),len(discount_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on flipkart tag on above, then find search bar, write on search bar and do click\n",
    "driver.find_element_by_xpath(\"//img[@class='_2xm1JU']\").click()\n",
    "search4job= driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search4job.send_keys(\"Sneakers\")\n",
    "search4btn= driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search4btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click on next button\n",
    "btn= driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click on next button again\n",
    "btn2= driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "btn2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching on URL\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list3=[]\n",
    "product_desc3=[]\n",
    "price_list3=[]\n",
    "discount_list3=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all required tags\n",
    "for i in urls[:35]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        brand=driver.find_element_by_xpath(\"//span[@class='G6XhRU']\")\n",
    "        brand_list3.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_list3.append('-')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@class='col col-11-12 _2cLjiM']\").click()\n",
    "        desc=driver.find_element_by_xpath(\"//div[@class='X3BRps _13swYk']\")\n",
    "        product_desc3.append(desc.text.replace('\\n',''))\n",
    "    except NoSuchElementException:\n",
    "        product_desc3.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        price=driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        price_list3.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        price_list3.append('-')  \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        discount=driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount_list3.append(discount.text)\n",
    "    except NoSuchElementException:\n",
    "        discount_list3.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 31 31 31\n"
     ]
    }
   ],
   "source": [
    "# Finding length of brand list, product description, price list, discount list of page 3\n",
    "print(len(brand_list3),len(product_desc3),len(price_list3),len(discount_list3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on flipkart tag on above, then find search bar, write on search bar and do click\n",
    "driver.find_element_by_xpath(\"//img[@class='_2xm1JU']\").click()\n",
    "search4job= driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search4job.send_keys(\"Sneakers\")\n",
    "search4btn= driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search4btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click on next button\n",
    "btn2= driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "btn2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click on next button again\n",
    "btn2= driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "btn2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do click on next button again\n",
    "btn3= driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "btn3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching on URL\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list4=[]\n",
    "product_desc4=[]\n",
    "price_list4=[]\n",
    "discount_list4=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all required tags\n",
    "for i in urls[:7]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        brand=driver.find_element_by_xpath(\"//span[@class='G6XhRU']\")\n",
    "        brand_list4.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_list4.append('-')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@class='col col-11-12 _2cLjiM']\").click()\n",
    "        desc=driver.find_element_by_xpath(\"//div[@class='X3BRps _13swYk']\")\n",
    "        product_desc4.append(desc.text.replace('\\n',''))\n",
    "    except NoSuchElementException:\n",
    "        product_desc4.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        price=driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        price_list4.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        price_list4.append('-')  \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        discount=driver.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount_list4.append(discount.text)\n",
    "    except NoSuchElementException:\n",
    "        discount_list4.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7 7 7\n"
     ]
    }
   ],
   "source": [
    "# Finding length of brand list, product description, price list, discount list of page 4\n",
    "print(len(brand_list4),len(product_desc4),len(price_list4),len(discount_list4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging page 1 2 3 data.\n",
    "brand=brand_list+brand_list2+brand_list3+brand_list4\n",
    "product=product_desc+product_desc2+product_desc3+product_desc4\n",
    "price=price_list+price_list2+price_list3+price_list4\n",
    "discount=discount_list+discount_list2+discount_list3+discount_list4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "# Finding length of brand list, product description, price list, discount list\n",
    "print(len(brand),len(product),len(price),len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "job7=pd.DataFrame({})\n",
    "job7['brand']=brand\n",
    "job7['product_desc']=product\n",
    "job7['price']=price\n",
    "job7['discount']=discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_desc</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>ColorBlueOuter materialMeshModel nameMen Sport...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>ColorBlack, BlueOuter materialCanvasModel name...</td>\n",
       "      <td>₹273</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>ColorWhiteInner materialCanvasOuter materialSy...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>ColorWhiteInner materialCanvasOuter materialMe...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>ColorWhite, BlackInner materialNapaOuter mater...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>asics</td>\n",
       "      <td>-</td>\n",
       "      <td>₹3,499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>ColorBlueOuter materialMeshModel nameTrenzo II...</td>\n",
       "      <td>₹1,256</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>ColorBlackInner materialFabricOuter materialCa...</td>\n",
       "      <td>₹1,000</td>\n",
       "      <td>23% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>ColorNavyOuter materialCanvasModel nameIcon ID...</td>\n",
       "      <td>₹1,220</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>bacca bucci</td>\n",
       "      <td>ColorBrownOuter materialSuedeModel nameMen's U...</td>\n",
       "      <td>₹998</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   brand                                       product_desc  \\\n",
       "0                BRUTON   ColorBlueOuter materialMeshModel nameMen Sport...   \n",
       "1   World Wear Footwear   ColorBlack, BlueOuter materialCanvasModel name...   \n",
       "2          Robbie jones   ColorWhiteInner materialCanvasOuter materialSy...   \n",
       "3               Numenzo   ColorWhiteInner materialCanvasOuter materialMe...   \n",
       "4          Robbie jones   ColorWhite, BlackInner materialNapaOuter mater...   \n",
       "..                   ...                                                ...   \n",
       "95                asics                                                   -   \n",
       "96                 PUMA   ColorBlueOuter materialMeshModel nameTrenzo II...   \n",
       "97                SPARX   ColorBlackInner materialFabricOuter materialCa...   \n",
       "98                 PUMA   ColorNavyOuter materialCanvasModel nameIcon ID...   \n",
       "99          bacca bucci   ColorBrownOuter materialSuedeModel nameMen's U...   \n",
       "\n",
       "     price discount  \n",
       "0     ₹299  76% off  \n",
       "1     ₹273  45% off  \n",
       "2     ₹379  62% off  \n",
       "3     ₹399  60% off  \n",
       "4     ₹474  52% off  \n",
       "..     ...      ...  \n",
       "95  ₹3,499  50% off  \n",
       "96  ₹1,256  58% off  \n",
       "97  ₹1,000  23% off  \n",
       "98  ₹1,220  63% off  \n",
       "99    ₹998  60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the link - https://www.myntra.com/shoes\n",
    "\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the link having filter price and color applied \n",
    "driver.get('https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A7649.0_15099.0_7649.0%20TO%2015099.0%2C6649.0_13099.0_6649.0%20TO%2013099.0%2C6612.0_13075.0_6612.0%20TO%2013075.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tag having brand name of first page\n",
    "brand=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "shoe_brand=[]\n",
    "for i in brand:\n",
    "    shoe_brand.append(i.text)\n",
    "print(len(shoe_brand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tag having description of first page\n",
    "description=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "short_desc=[]\n",
    "for i in description:\n",
    "    short_desc.append(i.text)\n",
    "print(len(short_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tag having price of first page\n",
    "price=driver.find_elements_by_xpath(\"//div[@class='product-price']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "shoe_price=[]\n",
    "for i in price:\n",
    "    shoe_price.append(i.text)\n",
    "print(len(shoe_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click next button to go on next page\n",
    "next_btn=driver.find_element_by_xpath(\"//a[@rel='next']\")\n",
    "next_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# So lets extract all tag having brand name of second page\n",
    "brand1=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "shoe_brand1=[]\n",
    "for i in brand1:\n",
    "    shoe_brand1.append(i.text)\n",
    "print(len(shoe_brand1))\n",
    "\n",
    "# So lets extract all tag having description of second page\n",
    "description1=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "short_desc1=[]\n",
    "for i in description1:\n",
    "    short_desc1.append(i.text)\n",
    "print(len(short_desc1))\n",
    "\n",
    "# So lets extract all tag having price of second page\n",
    "price1=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "shoe_price1=[]\n",
    "for i in price1:\n",
    "    shoe_price1.append(i.text)\n",
    "print(len(shoe_price1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging 1st and 2nd page data\n",
    "brand=shoe_brand+shoe_brand1\n",
    "description=short_desc+short_desc1\n",
    "price=shoe_price+shoe_price1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "# Finding length of brand, description and price\n",
    "print(len(brand),len(description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "job8=pd.DataFrame({})\n",
    "job8['brand']=brand\n",
    "job8['description']=description\n",
    "job8['price']=price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 7721Rs. 10295(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women REACT ESCAPE Running</td>\n",
       "      <td>Rs. 6636Rs. 8295(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Mercedes Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women REACT Running Shoes</td>\n",
       "      <td>Rs. 8396Rs. 11995(Rs. 3599 OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 11242Rs. 14990(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men REACT MILER 2 Running</td>\n",
       "      <td>Rs. 9770Rs. 11495(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Monks</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Oxfords</td>\n",
       "      <td>Rs. 13490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              brand                        description  \\\n",
       "0              Nike         Men AIR ZOOM Running Shoes   \n",
       "1              Nike         Women REACT ESCAPE Running   \n",
       "2   PUMA Motorsport      Unisex Mercedes Running Shoes   \n",
       "3              Nike          Women REACT Running Shoes   \n",
       "4              Nike        Men JORDAN DELTA Basketball   \n",
       "..              ...                                ...   \n",
       "95             Geox        Men Leather Formal Slip-Ons   \n",
       "96             Nike          Men REACT MILER 2 Running   \n",
       "97            Ruosh     Men Solid Leather Formal Monks   \n",
       "98            Ruosh  Men Solid Leather Formal Slip-Ons   \n",
       "99            Ruosh   Men Solid Leather Formal Oxfords   \n",
       "\n",
       "                              price  \n",
       "0        Rs. 7721Rs. 10295(25% OFF)  \n",
       "1         Rs. 6636Rs. 8295(20% OFF)  \n",
       "2                          Rs. 7999  \n",
       "3   Rs. 8396Rs. 11995(Rs. 3599 OFF)  \n",
       "4                         Rs. 12495  \n",
       "..                              ...  \n",
       "95      Rs. 11242Rs. 14990(25% OFF)  \n",
       "96       Rs. 9770Rs. 11495(15% OFF)  \n",
       "97                         Rs. 6990  \n",
       "98                         Rs. 6990  \n",
       "99                        Rs. 13490  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "url6='https://www.amazon.in/'\n",
    "driver.get(url6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding element for job search bar\n",
    "search_bar=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_bar.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click using xpath function\n",
    "btn=driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering into Intel core i7.\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tag having titles\n",
    "title=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_title=[]\n",
    "for i in title:\n",
    "    laptop_title.append(i.text)\n",
    "laptop_title=laptop_title[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(laptop_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having price.\n",
    "price=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_price=[]\n",
    "for i in price:\n",
    "    laptop_price.append(i.text)\n",
    "laptop_price=laptop_price[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching URL\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "urls=urls[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having ratings.\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        star=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "        rating.append(star.text)\n",
    "    except NoSuchElementException:\n",
    "        rating.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.4 out of 5',\n",
       " '4.6 out of 5',\n",
       " '2.9 out of 5',\n",
       " '4.4 out of 5',\n",
       " '3.5 out of 5']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do click on clear button in filter to remove previous applied filter\n",
    "cost=driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "cost.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering into Intel core i9.\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having titles.\n",
    "title2=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_title2=[]\n",
    "for i in title2:\n",
    "    laptop_title2.append(i.text)\n",
    "laptop_title2=laptop_title2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(laptop_title2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having price.\n",
    "price2=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_price2=[]\n",
    "for i in price2:\n",
    "    laptop_price2.append(i.text)\n",
    "laptop_price2=laptop_price2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(laptop_price2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.amazon.in/gp/slredirect/picassoRedirect.html/ref=pa_sp_atf_computers_sr_pg1_1?ie=UTF8&adId=A038310339RQD17Y8YFCH&url=%2FDell-9570-15-6-inch-i9-8950HK-Integrated%2Fdp%2FB08C5FMBLB%2Fref%3Dsr_1_1_sspa%3Fdchild%3D1%26keywords%3DLaptop%26qid%3D1621711433%26refinements%3Dp_n_feature_thirteen_browse-bin%253A16757432031%26rnid%3D12598141031%26s%3Dcomputers%26sr%3D1-1-spons%26psc%3D1&qualifier=1621711433&id=1126954408028054&widgetName=sp_atf',\n",
       " 'https://www.amazon.in/ASUS-Zephyrus-i9-10980HK-RTX-2080-SUPER-Max-Q-GX550LXS-HF168TS/dp/B08PFBB6RG/ref=sr_1_2?dchild=1&keywords=Laptop&qid=1621711433&refinements=p_n_feature_thirteen_browse-bin%3A16757432031&rnid=12598141031&s=computers&sr=1-2',\n",
       " 'https://www.amazon.in/ASUS-i9-10980HK-Touchscreen-Celestial-UX581LV-H2035T/dp/B08CHDLVT1/ref=sr_1_3?dchild=1&keywords=Laptop&qid=1621711433&refinements=p_n_feature_thirteen_browse-bin%3A16757432031&rnid=12598141031&s=computers&sr=1-3',\n",
       " 'https://www.amazon.in/Lenovo-Legion-Windows-Graphics-81YU006HIN/dp/B08GG9RZJC/ref=sr_1_4?dchild=1&keywords=Laptop&qid=1621711433&refinements=p_n_feature_thirteen_browse-bin%3A16757432031&rnid=12598141031&s=computers&sr=1-4',\n",
       " 'https://www.amazon.in/Dell-9570-15-6-inch-i9-8950HK-Integrated/dp/B08C5FMBLB/ref=sr_1_5?dchild=1&keywords=Laptop&qid=1621711433&refinements=p_n_feature_thirteen_browse-bin%3A16757432031&rnid=12598141031&s=computers&sr=1-5']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching URL\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "urls=urls[0:5]\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets extract all tags having ratings.\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        star=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "        rating2.append(star.text)\n",
    "    except NoSuchElementException:\n",
    "        rating2.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.4 out of 5', '-', '3.8 out of 5', '3.7 out of 5', '2.4 out of 5']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging list 1 2 of title, price and rating. \n",
    "title=laptop_title+laptop_title2\n",
    "price=laptop_price+laptop_price2\n",
    "rating=rating+rating2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Finding length of title, price, rating.\n",
    "print(len(title),len(price),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "job9=pd.DataFrame({})\n",
    "job9['title']=title\n",
    "job9['rating']=rating\n",
    "job9['price']=price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>1,07,790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS ZenBook Flip S OLED, Intel Evo Core i7-11...</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "      <td>1,49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>2.9 out of 5</td>\n",
       "      <td>47,050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>49,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Inspiron 5406 14\" FHD Touch Display 2in1 ...</td>\n",
       "      <td>3.5 out of 5</td>\n",
       "      <td>93,410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dell XPS 9570 15.6\" (39.62cms) UHD Laptop (8th...</td>\n",
       "      <td>2.4 out of 5</td>\n",
       "      <td>2,48,790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS ROG Zephyrus Duo 15, 15.6\" FHD 300Hz/3ms,...</td>\n",
       "      <td>-</td>\n",
       "      <td>2,66,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "      <td>2,99,325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...</td>\n",
       "      <td>3.7 out of 5</td>\n",
       "      <td>2,62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell XPS 9570 15.6\" (39.62cms) UHD Laptop (8th...</td>\n",
       "      <td>2.4 out of 5</td>\n",
       "      <td>2,48,790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        rating     price\n",
       "0  ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...  4.4 out of 5  1,07,790\n",
       "1  ASUS ZenBook Flip S OLED, Intel Evo Core i7-11...  4.6 out of 5  1,49,990\n",
       "2  Life Digital Laptop 15.6-inch (39.62 cms) (Int...  2.9 out of 5    47,050\n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.4 out of 5    49,999\n",
       "4  Dell Inspiron 5406 14\" FHD Touch Display 2in1 ...  3.5 out of 5    93,410\n",
       "5  Dell XPS 9570 15.6\" (39.62cms) UHD Laptop (8th...  2.4 out of 5  2,48,790\n",
       "6  ASUS ROG Zephyrus Duo 15, 15.6\" FHD 300Hz/3ms,...             -  2,66,990\n",
       "7  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  3.8 out of 5  2,99,325\n",
       "8  Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...  3.7 out of 5  2,62,990\n",
       "9  Dell XPS 9570 15.6\" (39.62cms) UHD Laptop (8th...  2.4 out of 5  2,48,790"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
